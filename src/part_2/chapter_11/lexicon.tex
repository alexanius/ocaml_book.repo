\section{Лексика}

Синтаксический анализ это предварительный и необходимый этап обработки
последовательностей символов: он разделяет этот поток в последовательность слов,
так называемых лексические единицы или лексемы.

\subsection{Модуль \texttt{Genlex}}

В данном модуле имеется элементарное средство для анализа символьного потока.
Для этого используются несколько категорий предопределенных лексических единиц.
Эти категории различаются по типу:

\begin{lstlisting}[language=Caml]
# type token = Kwd of string
    | Ident of string
    | Int of int
    | Float of float
    | String of string
    | Char of char ;;
\end{lstlisting}

Таким образом мы можем разузнать в потоке символов целое число (конструктор
\texttt{Int}) и получить его значение (аргумент конструктора \texttt{int}).
Распознаваемые символы и строки подчиняются следующим общепринятым соглашением:
строка окружена символами ("), а символ окружен ('). Десятичное число
представлено либо используя запись с точкой (например 0.01), либо с мантиссой и
экспонентой (на пример 1E-2). Кроме этого остались конструкторы \texttt{Kwd} и
\texttt{Ident}.

Конструктор \texttt{Ident} предназначен для определения идентификаторов.
Идентификатором может быть имя переменной или функции языка программирования.
Они состоят из какой угодно последовательности букв и цифр, могут включать
символ подчеркивания (\_) или апостроф ('). Данная последовательность не должна
начинаться с цифры. Любая последовательность следующих операндов тоже будет
считаться идентификатором: +,*,> или -. И наконец, конструктор Kwd определяет
категорию специальных идентификаторов или символов.

Категория ключевых слова --- единственная из этого множества, которую можно
сконфигурировать. Для того, чтобы создать лексический анализатор, воспользуемся
следующей конструкцией, которой необходимо передать список ключевых слов на
место первого аргумента.

\begin{lstlisting}[language=Caml]
# Genlex.make_lexer ;;
- : string list -> char Stream.t -> Genlex.token Stream.t = <fun>
\end{lstlisting}

Тем самым получаем функцию, которая принимает на вход поток символов и
возвращает поток лексических единиц (с типом \texttt{token}).

Таким образом, мы без труда реализуем лексический анализатор для интерпретатора
BASIC. Объявим множество ключевых слов:

\begin{lstlisting}[language=Caml]
# let keywords =
    [ "REM"; "GOTO"; "LET"; "PRINT"; "INPUT"; "IF"; "THEN"; "-";
    "!"; "+"; "-"; "*"; "/"; "%";
    "="; "<"; ">"; "<="; ">="; "<>";
    "&"; "|" ] ;;
\end{lstlisting}

При помощи данного множества, определим функцию лексического анализа:

\begin{lstlisting}[language=Caml]
# let line_lexer l = Genlex.make_lexer keywords (Stream.of_string l) ;;
val line_lexer : string -> Genlex.token Stream.t = <fun>
# line_lexer "LET x = x + y * 3" ;;
- : Genlex.token Stream.t = <abstr>
\end{lstlisting}

Приведенная функция \texttt{line\_lexer}, из входящего потока символов создает
поток соответствующих лексем.

\subsection{Использование потоков}

Мы также можем реализовать лексический анализ \enq{в ручную} используя потоки.

В следующем примере определен лексический анализатор арифметических выражений.
Функции lexer передается поток символов из которого она создает поток
лексических единиц с типом \texttt{lexeme Stream.t} \footnote{тип
\texttt{lexeme} определен на стр. \cite{??}}. Символы пробел, табуляция и
переход на новую строку удаляются. Для упрощения, мы не будем обрабатывать
переменные и отрицательны целые числа.

\begin{lstlisting}[language=Caml]
# let rec spaces s =
    match s with parser
      [<'' ' ; rest >] -> spaces rest
      | [<''\t' ; rest >] -> spaces rest
      | [<''\n' ; rest >] -> spaces rest
      | [<>] -> ();;
val spaces : char Stream.t -> unit = <fun>
# let rec lexer s =
   spaces s;
   match s with parser
     [< ''(' >] -> [< 'Lsymbol "("; lexer s >]
     | [< '')' >] -> [< 'Lsymbol ")"; lexer s >]
     | [< ''+' >] -> [< 'Lsymbol "+" ; lexer s >]
     | [< ''-' >] -> [< 'Lsymbol "-" ; lexer s >]
     | [< ''*' >] -> [< 'Lsymbol "*" ; lexer s >]
     | [< ''/' >] -> [< 'Lsymbol "/" ; lexer s >]
     | [< ''0'..'9' as c;
       i,v = lexint (Char.code c - Char.code('0')) >]
       ->[<'Lint i ; lexer v>]
   and lexint r s =
     match s with parser
       [< ''0'..'9' as c >]
       -> let u = (Char.code c) - (Char.code '0') in lexint (10*r + u) s
       | [<>] -> r,s ;;
val lexer : char Stream.t -> lexeme Stream.t = <fun>
val lexint : int -> char Stream.t -> int * char Stream.t = <fun>
\end{lstlisting}

Функция lexint предназначена для анализа той части потока символов, которая
соответствует числовой постоянной. Она вызывается, когда функция \texttt{lexer}
встречает цифры. В этом случае функция \texttt{lexint} поглощает все
последовательные цифры и выдает соответствующее значение полученного числа.

\section{Регулярные выражения}

Оставим ненадолго практику и рассмотрим проблему лексических единиц с
теоретической точки зрения.

Лексическая единица является словом. Слово образуется при конкатенации элементов
алфавита. В нашем случае алфавитом является множество символов ASCII.

Теоретически, слово может вообще не содержать символов (пустое слово
\footnote{традиционно, такое слово обозначается греческой буквой эпсилон:
$\varepsilon$}) или состоять из одного символа.

Теоретические исследования конкатенации элементов алфавита для образования
лексических элементов (лексем) привели к созданию простого формализма,
известного как рациональные выражения.

\subsubsection{Определение}

Регулярные выражения позволяют определить множества слов. Пример такого
множества: идентификаторы. Принцип определения основан на некоторых
теоретико–множественный операциях. Пусть $M$ и $N$ два множества слов, тогда мы
можем определить:

\begin{itemize}
	\item объединение $M$ и $N$, записываемое $M | N$.

	\item дополнение $М$, записываемое $\wedge M$: множество всех слов, кроме
тех, которые входят в $M$.

	\item конкатенация $M$ и $N$: множество всех слов созданных конкатенацией
слова из $M$ и слова из $N$. Записывается просто $MN$.

	\item мы можем повторить операцию конкатенации слов множества $M$ и тем
самым получить множество слов образованных из конечной последовательности слов
множеств $M$. Такое множество записывается $M+$. Он содержит все слова множества
$M$, все слова полученные конкатенацией двух слов множества $M$, трех слов, и
т.д. Если мы желаем чтобы данное множество содержало пустое слово, необходимо
писать $M*$.

	\item для удобства, существует дополнительная конструкция $M?$, которая
включает все слова множества $M$, а так же пустое слово.
\end{itemize}

Один единственный символ ассоциируется с одноэлементным множеством. В таком
случае выражение {\it a| b| c} описывает множество состоящее из трех слов
{\it a}, {\it b} и {\it c}. Существует более компактная запись: {\it [abc]}.
Так как наш алфавит является упорядоченным (по порядку кодов ASCII), можно
определить интервал. Например, множество цифр запишется как $[0-9]$. Для
группировки выражений можно использовать скобки.

Для того, чтобы использовать в записи сами символы–операторы, как обычные
символы, необходимо ставить перед ними обратную косую черту: $\backslash$.
Например множество $(\backslash *)*$ обозначает множество последовательностей
звездочек.

\subsubsection{Пример}

Пусть существует множество из цифр (0,1,2,3,4,5,6,7,8,9), символы плюс ($+$) и
минус ($-$), точки ($.$) и буквы $E$. Теперь мы можем определить множество чисел
{\it num}. Назовем {\it integers} множество определенное выражением $[0-9]+$.
Множество неотрицательных чисел {\it unum} определяется так:
$$
	\text{\it integers} ? (.\text{\it integers}) ? (E(\backslash+|-) ? \\
\text{\it integers})?
$$

Множество отрицательных и положительных чисел записывается:

$$
\text{\it unum} | -\text{\it unum} \quad \text{или} \quad -?\text{\it unum}
$$

\subsubsection{Распознавание}

Теперь, после того как множество выражений определено, остается проблема
распознавания принадлежности строки символов или одной из ее подстрок этому
множеству. Для решения данной задачи необходимо реализовать программу обработки
выражений, которая соответствует формальным определениям множества. Для
рациональных выражений такая обработка может быть автоматизированна. Подобная
автоматизация реализована в модуле \texttt{Genlex} из библиотеки \texttt{Str} и
инструментом \texttt{ocamllex}, которые будут представлены в следующих двух
параграфах.

\subsubsection{Библиотека \texttt{Str}}

В данном модуле имеется абстрактный тип \texttt{regexp} и функция
\texttt{regexp}. Указанный тип представляет рациональные выражения, а функция
трансформирует рациональное выражение, представленное в виде строки символов, в
абстрактное выражение.

Модуль \texttt{Str} содержит несколько функций, которые используют рациональные
выражения и манипулируют символьными строками. Синтаксис рациональных выражений
библиотеки \texttt{Str} приведён в таблице \ref{tbl:reg_exps}.

\begin{table}[hс]
	\caption{Регулярные выражения}
	\begin{tabular}{|c|p{12.5cm}|}
	\hline
	$.$ & любой символ, кроме $\backslash$ \\
	\hline
	$*$ & ноль или несколько экземпляров предыдущего выражения \\
	\hline
	$+$ & хотя бы один экземпляр предыдущего выражения \\
	\hline
	$?$ & ноль или один экземпляр предыдущего выражения \\
	\hline
	$[..]$ & множество символов \\
	\hline
	$.$ & любой символ, кроме $\backslash$ \\
	\hline
	 & интервал записывается при помощи - (пример $[0-9]$) \\
	 \hline
	 & дополнение записывается при помощи $\wedge$ (пример $[\wedge A-Z]$) \\
	 \hline
	$\wedge$ & начало строки (не путать с дополнением $\wedge$) \\
	 \hline
	$\$$ & конец строки \\
	 \hline
	$|$ & вариант \\
	 \hline
	$(..)$ & группировка в одно выражение (можно ссылаться на это выражение) \\
	 \hline
	$i$ & числовая константа $i$ ссылается на $i$--ый элемент группированного
выражения \\
	 \hline
	$\backslash$ & забой, используется для сопоставления зарезервированных
символов в рациональных выражениях \\
	 \hline
	\end{tabular}
	\label{tbl:reg_exps}
\end{table}

\subsubsection{Пример}

В следующем примере напишем функцию, которая переводит дату из английского
формата во французский. Предполагается, что входной файл состоит из строк,
разбитых на поля данных и элементы даты разделяются точкой. Определим функцию,
которая из полученной строки (линия файла), выделяет дату, разбивает её на
части, переводит во французских формат и тем самым заменяет старую дату на
новую.

\begin{lstlisting}[language=Caml]
# let french_date_of d =
  match d with
   [mm; dd; yy] -> dd^"/"^mm^"/"^yy
   | _ -> failwith "Bad date format" ;;
val french_date_of : string list -> string = <fun>

# let english_date_format = Str.regexp "[0-9]+\.[0-9]+\.[0-9]+" ;;
val english_date_format : Str.regexp = <abstr>

# let trans_date l =
  try
  let i=Str.search_forward english_date_format l 0 in
  let d1 = Str.matched_string l in
  let d2 = french_date_of (Str.split (Str.regexp "\.") d1) in
    Str.global_replace english_date_format d2 l
  with Not_found -> l ;;
  val trans_date : string -> string = <fun>

# trans_date
"..............06.13.99............" ;;
- : string = "..............13/06/99............"
\end{lstlisting}

\subsection{Инструмент \texttt{Ocamllex}}

\texttt{ocamllex} --- это лексический генератор созданный для Objective CAML по
модели \texttt{lex}, написанном на языке C. При помощи файла, описывающего
элементы лексики в виде множества рациональных выражений, которые необходимо
распознать, он создаёт файл--исходник на Objective CAML. К описанию каждого
лексического элемента можно привязать какое--нибудь действие, называемое
семантическое действие. В полученном коде используется абстрактный тип
\texttt{lexbuf} из модуля \texttt{Lexing}. В данном модуле также имеется
несколько функций управления лексическими буферами, которые могут быть
использованы программистом для того чтобы определить необходимые действия.

Обычно, файлы, описывающие лексику, имеют расширение \texttt{.mll}. Для того,
чтобы из файла \texttt{lex\_file.mll} получить файл на Objective CAML,
необходимо выполнить следующую команду:

\begin{lstlisting}[language=Caml]
ocamllex lex_file.mll
\end{lstlisting}

После этого, мы получим файл \texttt{lex\_file.ml}, содержащий код лексического
анализатора. Теперь, данный файл можно использовать в программе на Objective
CAML. Каждому множеству правил анализа соответствует функция, которая принимает
лексический буфер (типа \texttt{Lexing.lexbuf}) и затем возвращает значение,
определённое семантическим действием. Значит, все действия для определённого
правила должны создавать значение одного и того же типа.

Формат у файла для \texttt{ocamllex} следующий:

\begin{lstlisting}[language=Caml]
{
  header
}
let ident = regexp
        ...
rule ruleset1 = parse
                regexp { action }
                | ...
                | regexp { action }
and ruleset2 = parse
        ...
and ...
{
  trailer-and-end
}
\end{lstlisting}

Части \enq{заголовок} и \enq{продолжение-и-конец} не являются обязательными.
Здесь вставляется код Objective CAML, определяющий типы данных, функции и т.д.
необходимые для обработки данных. В последней части используются функции,
которые используют правила анализа множества лексических данных из средней
части. Серия объявлений, которая предшествует определению правил, позволяет дать
имя некоторым рациональным выражениям. Эти имена будут использоваться в
определении правил.

\subsubsection{Пример}

Вернёмся к нашему интерпретатору BASIC и усовершенствуем тип возвращаемых
лексических единиц. Таким образом, мы можем воспользоваться функцией
\texttt{lexer}, (см. стр.  \ref{??}) которая возвращает такой же тип результата
(\texttt{lexeme}), но на входе она получает буфер типа \texttt{Lexing.lexbuf}.

\begin{lstlisting}[language=Caml]
  {
    let string_chars s =
    String.sub s 1 ((String.length s)-2) ;;
  }

let op_ar = ['-' '+' '*' '\%' '/']
let op_bool = ['!' '\&' '|']
let rel = ['=' '<' '>']

rule lexer = parse
    [' ']   { lexer lexbuf }
  | op_ar   { Lsymbol (Lexing.lexeme lexbuf) }
  | op_bool { Lsymbol (Lexing.lexeme lexbuf) }
  | "<="    { Lsymbol (Lexing.lexeme lexbuf) }
  | ">="    { Lsymbol (Lexing.lexeme lexbuf) }
  | "<>"    { Lsymbol (Lexing.lexeme lexbuf) }
  | rel     { Lsymbol (Lexing.lexeme lexbuf) }
  | "REM"   { Lsymbol (Lexing.lexeme lexbuf) }
  | "LET"   { Lsymbol (Lexing.lexeme lexbuf) }
  | "PRINT" { Lsymbol (Lexing.lexeme lexbuf) }
  | "INPUT" { Lsymbol (Lexing.lexeme lexbuf) }
  | "IF"    { Lsymbol (Lexing.lexeme lexbuf) }
  | "THEN"  { Lsymbol (Lexing.lexeme lexbuf) }
  | '-'? ['0'-'9']+   { Lint (int_of_string (Lexing.lexeme lexbuf)) }
  | ['A'-'z']+        { Lident (Lexing.lexeme lexbuf) }
  | '"' [^ '"']* '"'  { Lstring (string_chars (Lexing.lexeme lexbuf)) }
\end{lstlisting}

После обработки данного файла командой \texttt{ocamllex} получим функцию
\texttt{lexer} типа \texttt{Lexing.lexbuf -> lexeme}. Далее, мы рассмотрим каким
образом подобные функции используются в синтаксическом анализе (см. стр.
\ref{??}).
